# Compliance Development Practices

> **Usage**: Include when working on any compliance-related features or when handling regulated data
> 
> **Constitutional Status**: These practices contain IMMUTABLE principles (marked ðŸ”’) that require formal amendment process to change, and FLEXIBLE guidelines that can evolve with project needs.

**Version**: 2.0.0 | **Ratified**: [Current Date] | **Last Amended**: [Current Date]

## Scope and Definitions

### Auditing vs. Logging

This document distinguishes between two critical but separate concerns:

- **AUDITING**: Ensures the integrity of database contents through immutable, tamper-evident records of all data modifications. Purpose: regulatory compliance, data integrity verification, forensic investigation. Audit trails are permanent records for compliance officers and regulators.

- **LOGGING**: Captures system events for debugging and performance evaluation. Purpose: troubleshooting, monitoring, performance optimization. Logs are operational tools for developers and may be rotated/archived based on retention policies.

**Critical Distinction**: Audit trails are compliance artifacts subject to regulatory requirements. Logs are operational artifacts subject to technical requirements. Never conflate the two.

## ðŸ”’ Constitutional Principles for AI-Assisted Development

> **IMMUTABLE**: These principles are non-negotiable and apply to all code, whether written by humans or generated by AI agents.

### AI Development Governance

When using AI-assisted development tools (Claude, GitHub Copilot, etc.), the following principles MUST be enforced:

1. **ðŸ”’ AI-Generated Code Validation (NON-NEGOTIABLE)**
   - All AI-generated code MUST undergo the same validation as human-written code
   - AI cannot bypass TDD requirements, compliance checks, or code review
   - AI-generated implementations MUST include full audit trail support
   - AI MUST follow ALCOA+ principles in all data handling code

2. **Constitutional Constraints for AI Agents**
   - AI must interpret requirements through the lens of these compliance practices
   - When generating code, AI must:
     - Include audit trail capture for all data modifications
     - Implement proper authentication/authorization checks
     - Follow encryption standards for sensitive data
     - Generate tests BEFORE implementation code
     - Apply library-first for major features (see Principle I for scope)
     - **Ask user when unclear**: "Should this be a library or direct implementation?"

3. **Library-First Decision Making for AI**
   - If ticket specifies "library" or "major feature" â†’ Use library-first
   - If ticket says "tweak", "fix", "adjust UI", "config" â†’ Direct implementation OK
   - If unclear from context:
     - AI MUST ask: "This appears to be [major feature/minor tweak]. Should I implement as a standalone library or direct application code?"
     - Provide recommendation based on: complexity, reusability potential, scope
     - Wait for user confirmation before proceeding

4. **AI Output Verification**
   - Human developer MUST verify that AI-generated code:
     - Captures required audit metadata
     - Implements proper error handling for compliance scenarios
     - Includes validation for regulatory requirements
     - Has no hardcoded credentials or sensitive data exposure
     - Correctly applied library-first vs. direct implementation decision
   
5. **Specification-Driven AI Development**
   - AI agents MUST work from complete specifications that define:
     - Compliance requirements explicitly
     - Expected audit trail behavior
     - Security constraints
     - Data integrity requirements
     - Whether feature is library-worthy (major) or direct implementation (minor)
   - Specifications serve as validation gates for AI output
   - Implementation plans generated by AI must pass constitutional checks

**Rationale**: AI accelerates development but cannot compromise compliance. These principles ensure AI serves our compliance standards rather than circumventing them. AI asking for clarification on library-first scope prevents both over-engineering (libraries for tweaks) and under-engineering (direct implementation for major features).

## Regulatory Framework Understanding

### Know Your Requirements

Before implementing compliance features, understand:

- **Which regulations apply**: FDA 21 CFR Part 11, GDPR, HIPAA, ISO 27001, SOC-2.
- **Specific requirements**: Read the actual regulation text, not just summaries
- **Interpretation**: Understand how your organization interprets requirements
- **Validation needs**: What evidence must be produced for audits

### Key Compliance Areas

1. **Data Integrity** (ALCOA+ Principles)
   - **A**ttributable: Who created or modified the data?
   - **L**egible: Is data readable and understandable?
   - **C**ontemporaneous: Recorded at the time of activity?
   - **O**riginal: First capture or certified true copy?
   - **A**ccurate: Free from errors, correct?
   - **+Complete**: All data captured?
   - **+Consistent**: Sequence of events logical?
   - **+Enduring**: Retained for required period?
   - **+Available**: Retrievable for review/audit?

2. **Electronic Signatures** (21 CFR Part 11.50)
   - Unique to one individual
   - Not reused or reassigned
   - Verified before use
   - Cryptographically secure

3. **Audit Trail** (21 CFR Part 11.10(e))
   - Secure, computer-generated, time-stamped
   - Records: date, time, who performed action, what changed
   - Independent of main record
   - Cannot be altered
   - Regularly reviewed
   - **Purpose**: Data integrity verification and regulatory compliance
   - **Not for**: Debugging, performance monitoring, or operational logging

## Implementation Requirements

### Audit Trail Implementation (Data Integrity)

> **Purpose**: Ensure database integrity through immutable records of data changes. This is NOT operational logging.

**Every data modification must be audited with**:

```
{
  "event_id": "unique identifier",
  "timestamp": "ISO 8601 UTC timestamp",
  "user_id": "authenticated user identifier",
  "user_name": "display name at time of action",
  "action": "CREATE | UPDATE | DELETE | SIGN",
  "entity_type": "what was modified",
  "entity_id": "specific record identifier",
  "before_value": "previous state (for updates)",
  "after_value": "new state",
  "reason": "reason for change (if required)",
  "session_id": "session identifier",
  "device_info": "device/platform information",
  "ip_address": "source IP (if applicable)",
  "hash": "cryptographic hash for tamper detection"
}
```

**Required Characteristics**:

âœ… Append-only (no updates or deletes to audit log)
âœ… Immutable (tamper-evident with cryptographic hashing)
âœ… Synchronized (captured at time of action, not batched)
âœ… Complete (captures all required metadata)
âœ… Retrievable (queryable for audits and investigations)
âœ… Retained (stored for required retention period)

**Implementation Pattern**:

```dart
// Example: Audit trail wrapper for all data operations
// NOTE: This is AUDITING (data integrity), not LOGGING (debugging)
Future<T> auditedDataOperation<T>({
  required String action,
  required String entityType,
  required String entityId,
  required Future<T> Function() operation,
  Map<String, dynamic>? beforeValue,
  Map<String, dynamic>? afterValue,
  String? reason,
}) async {
  final auditEntry = AuditEntry(
    eventId: Uuid().v4(),
    timestamp: DateTime.now().toUtc(),
    userId: currentUser.id,
    userName: currentUser.displayName,
    action: action,
    entityType: entityType,
    entityId: entityId,
    beforeValue: beforeValue,
    afterValue: afterValue,
    reason: reason,
    sessionId: currentSession.id,
    deviceInfo: DeviceInfo.current,
  );
  
  try {
    final result = await operation();
    auditEntry.status = 'SUCCESS';
    await auditTrail.append(auditEntry);  // Audit trail, not log
    return result;
  } catch (e) {
    auditEntry.status = 'FAILED';
    auditEntry.errorDetails = e.toString();
    await auditTrail.append(auditEntry);  // Audit trail, not log
    rethrow;
  }
}
```

### Authentication & Authorization

**Authentication Requirements**:

- Multi-factor authentication for high-risk operations
- Password complexity requirements
- Account lockout after failed attempts
- Session timeout enforcement
- Secure password storage (never plaintext)
- Password reset with verification

**Authorization Requirements**:

- Role-based access control (RBAC)
- Principle of least privilege
- Verify permissions at every access point
- Document permission matrix
- Regular access reviews

**Implementation Checklist**:

- [ ] User authentication verified before any operation
- [ ] Session tokens cryptographically secure
- [ ] Sessions expire after inactivity
- [ ] Roles and permissions clearly defined
- [ ] Authorization checked on backend (never trust client)
- [ ] Permission changes are audited
- [ ] User account actions are audited (login, logout, password change)

### Data Encryption

**Encryption at Rest**:

- All sensitive data encrypted in database
- Use industry-standard algorithms (AES-256)
- Proper key management (never hardcode keys)
- Key rotation policy
- Secure key storage (hardware keystores when possible)

**Encryption in Transit**:

- TLS 1.2 or higher for all network communication
- Certificate pinning for sensitive apps
- No mixed content (all resources over HTTPS)
- Secure WebSocket connections (WSS)

**Implementation Checklist**:

- [ ] Database encrypted (e.g., SQLCipher)
- [ ] Encryption keys stored in secure keystore
- [ ] Sensitive fields additionally encrypted
- [ ] All API calls use HTTPS
- [ ] Certificate validation enabled
- [ ] No sensitive data in URLs or logs

### Validation and Testing

**Compliance Testing Requirements**:

1. **Functional Testing**
   - Verify all compliance features work as designed
   - Test audit trail captures all required events
   - Test authentication and authorization enforcement
   - Test data encryption and decryption

2. **Security Testing**
   - Penetration testing
   - Vulnerability scanning
   - Access control verification
   - Encryption validation

3. **Audit Trail Testing**
   - Verify completeness (all events captured)
   - Verify accuracy (correct metadata)
   - Verify tamper-evidence (hash validation)
   - Verify retention (data persists as required)

4. **Traceability Testing**
   - Requirements traceability matrix
   - Map each requirement to test case
   - Map each test case to implementation
   - Document test results

**Test Data Management**:

- Never use real PHI/PII in test environments
- Generate realistic synthetic data
- Sanitize production data before using for testing
- Follow data privacy regulations even for test data


**Documentation Standards**:

- Version control all documentation
- Maintain change history
- Regular review and updates
- Accessible for audits

### Change Control

**All changes to validated systems require**:

1. **Change Request**
   - Description of change
   - Justification (why needed)
   - Impact assessment (what's affected)
   - Risk assessment

2. **Approval**
   - Technical review
   - Quality assurance review
 
3. **Implementation**
   - Follow development standards
   - Update all affected documentation
   - Perform regression testing
   - Update validation if needed

4. **Verification**
   - Test changes work as intended
   - Verify no adverse impacts
   - Review audit trail

5. **Documentation**
   - Update user documentation
   - Update technical documentation
   - Record in change log
   - Close change request

**Emergency Changes**:

- Documented procedure for urgent fixes
- Retrospective approval process
- Complete documentation required
- Must not bypass critical controls

## Compliance Don'ts

âŒ **Never** disable audit trail capture for any reason
âŒ **Never** modify historical audit records
âŒ **Never** share authentication credentials
âŒ **Never** store passwords in plain text
âŒ **Never** skip validation testing "to save time"
âŒ **Never** use production data in test environments
âŒ **Never** make undocumented changes to validated systems
âŒ **Never** assume compliance - verify and document
âŒ **Never** implement compliance features without understanding requirements
âŒ **Never** delete data that may be subject to retention requirements
âŒ **Never** conflate audit trails (compliance) with operational logs (debugging)

## Data Privacy (GDPR, HIPAA, etc.)

### Core Principles

1. **Data Minimization**: Collect only necessary data
2. **Purpose Limitation**: Use data only for stated purposes
3. **Storage Limitation**: Retain only as long as necessary
4. **Accuracy**: Keep data accurate and up to date
5. **Integrity & Confidentiality**: Protect against unauthorized access
6. **Accountability**: Demonstrate compliance

### Implementation Requirements

**User Consent**:
- Clear, specific consent for data collection
- Ability to withdraw consent
- Document consent with timestamp and version

**User Rights**:
- Right to access their data
- Right to correct inaccurate data
- Right to delete data (with retention requirements exceptions)
- Right to data portability
- Right to object to processing

**Data Breach Response**:
- Detection and logging of security incidents
- Incident response procedure
- Notification requirements (72 hours for GDPR)
- Documentation of breaches and response

### Implementation Checklist

- [ ] Privacy policy clear and accessible
- [ ] Consent mechanism implemented
- [ ] User can view their own data
- [ ] User can export their data
- [ ] User can request deletion (with compliant handling of retention requirements)
- [ ] Data processing agreements with third parties
- [ ] Breach detection and notification procedures
- [ ] Data protection impact assessment (DPIA) completed

## ðŸ”’ Observability Requirements (Debugging & Performance)

> **Purpose**: Enable debugging, monitoring, and performance evaluation through structured operational logging. This is separate from audit trails.

### Distinction from Audit Trails

**Audit Trails**: Immutable compliance records of data changes
**Operational Logs**: Diagnostic information for system health and performance

### Mandatory Observability Standards

1. **ðŸ”’ Structured Logging (NON-NEGOTIABLE)**
   - All components MUST use structured logging (JSON format)
   - Every log entry MUST include:
     - `timestamp`: ISO 8601 UTC
     - `level`: DEBUG, INFO, WARN, ERROR, FATAL
     - `component`: Which module/service generated the log
     - `correlation_id`: Request/transaction identifier
     - `message`: Human-readable description
     - `context`: Structured metadata (JSON object)
   
2. **Log Levels and Usage**
   - **DEBUG**: Detailed diagnostic information for development
   - **INFO**: Normal operations, significant events
   - **WARN**: Unexpected but handled situations
   - **ERROR**: Errors that prevented operation completion
   - **FATAL**: System failure requiring immediate attention

3. **What to Log (Operational)**
   - System startup/shutdown events
   - External service calls (with duration)
   - Database query performance metrics
   - Cache hits/misses
   - Business process milestones
   - Errors with full stack traces and context
   
4. **What NOT to Log**
   - Passwords, API keys, tokens, or credentials
   - Personally Identifiable Information (PII)
   - Protected Health Information (PHI)
   - Complete audit trail data (use audit system instead)
   - Sensitive business data covered by regulations

5. **Performance Monitoring**
   - Log execution time for operations >100ms
   - Track database query counts per request
   - Monitor memory usage for batch operations
   - Record API response times
   - Capture queue depths and processing rates

6. **Log Retention (Operational)**
   - Production logs: 90 days minimum (configurable)
   - Debug logs: 30 days (can be shorter)
   - Error logs: 1 year (for pattern analysis)
   - Performance metrics: 1 year (for trending)
   - **Note**: Audit trail retention follows regulatory requirements (typically 7+ years)

### Implementation Requirements

```dart
// Example: Structured logging pattern
class OperationalLogger {
  void logOperation({
    required String component,
    required String operation,
    required String correlationId,
    required Duration duration,
    Map<String, dynamic>? context,
  }) {
    final logEntry = {
      'timestamp': DateTime.now().toUtc().toIso8601String(),
      'level': 'INFO',
      'component': component,
      'correlation_id': correlationId,
      'message': 'Operation completed',
      'operation': operation,
      'duration_ms': duration.inMilliseconds,
      'context': context ?? {},
    };
    
    // Send to logging infrastructure (NOT audit trail)
    logger.info(jsonEncode(logEntry));
  }
  
  void logError({
    required String component,
    required String correlationId,
    required String message,
    required dynamic error,
    StackTrace? stackTrace,
  }) {
    final logEntry = {
      'timestamp': DateTime.now().toUtc().toIso8601String(),
      'level': 'ERROR',
      'component': component,
      'correlation_id': correlationId,
      'message': message,
      'error': error.toString(),
      'stack_trace': stackTrace?.toString(),
    };
    
    // Send to logging infrastructure for debugging
    logger.error(jsonEncode(logEntry));
  }
}
```

### Observability Checklist

- [ ] All components implement structured logging
- [ ] Correlation IDs flow through entire request chain
- [ ] Performance metrics captured for critical operations
- [ ] Error logs include full context and stack traces
- [ ] No sensitive data in operational logs
- [ ] Log aggregation system configured (e.g., ELK, Splunk)
- [ ] Alerts configured for ERROR and FATAL levels
- [ ] Dashboard for real-time system health monitoring
- [ ] Clear separation between audit trails and operational logs

### Standards and Regulations

- FDA 21 CFR Part 11: Electronic Records and Electronic Signatures
- GCP 5: Good Clinical Practice
- GDPR: General Data Protection Regulation
- HIPAA: Health Insurance Portability and Accountability Act
- ICH E6(R2): Good Clinical Practice

### Best Practices

- ALCOA+ principles for data integrity
- NIST Cybersecurity Framework
- OWASP Top 10 security risks
- Secure development lifecycle (SDL)

Remember: Compliance is not a one-time activity but an ongoing commitment. When in doubt, document your decision-making process and consult with compliance experts.

---

## Continuous Compliance

### Regular Activities

**Weekly**:
- Review audit trails for data integrity anomalies
- Monitor operational logs for system errors and warnings
- Check for dependency vulnerabilities
- Analyze performance metrics from logs

**Monthly**:
- Review access controls
- Audit user accounts and permissions
- Review compliance test results

**Quarterly**:
- Update risk assessment
- Review and test disaster recovery
- Training on compliance requirements
- Review and update documentation

**Annually**:
- Full compliance audit
- Penetration testing
- Review and update SOPs
- Regulatory update review
- Validation maintenance

### When to Involve Compliance Experts

Involve quality assurance and regulatory specialists for:

- Initial system design
- Major architectural changes
- New compliance requirements
- Audit findings
- Regulatory submissions
- Interpretation of regulations
- Risk assessments

### Reference Material

https://www.fda.gov/drugs/cder-small-business-industry-assistance-sbia/regulatory-education-industry-redi-fda-mhra-good-clinical-practice-workshop-data-integrity-global

---

**Source Files**:
- Original dev-compliance-practices.md
- dev-continuous-compliance.md (merged 2025-10-17)
